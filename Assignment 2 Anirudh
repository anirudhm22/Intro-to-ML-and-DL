import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

class LinearRegression:
    def __init__(self, learning_rate, epochs):
        self.lr=learning_rate
        self.epochs=epochs

    def fit(self, X_train, y_train):
        n_samples, n_features = X_train.shape
        y_train=y_train.reshape(-1,1)
        # init parameters
        self.weights = np.zeros((n_features,1))
        self.bias = np.zeros((1,1))

        # gradient descent
        for i in range(self.epochs):
            delta= -(y_train-np.dot(X_train,self.weights)-self.bias)/n_samples
            dw= np.dot(X_train.T,delta)
            db= np.sum(delta).reshape(1,1)

            #update weights and biases
            self.weights-= self.lr * dw
            self.bias-= self.lr* db

    def predict(self, X_test):
        y_predicted = np.dot(X_test,self.weights)+self.bias
        print(self.weights, self.bias)
        return y_predicted

X, y = make_regression(n_samples=1000, n_features=1, noise=10, random_state= 42 )  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)
lr_model = LinearRegression(0.001,2500)
lr_model.fit(X_train, y_train)
y_predicted = lr_model.predict(X_test)

y_pred = lr_model.predict(X_train)
plt.scatter(X_train, y_train, color='blue', label='Training Data')
plt.scatter(X_test, y_test, color='yellow', label='Testing Data')
plt.plot(X_test, y_predicted, color='red', linewidth=2, label='Line of Best Fit')

plt.scatter(X_train, y_train, color='blue', label='Training Data')
plt.scatter(X_test, y_test, color='yellow', label='Testing Data')
plt.plot(X_test, y_predicted, color='red', linewidth=2, label='Line of Best Fit')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()

mse = mean_squared_error(y_train, lr_model.predict(X_train))
print('Mean Squared Error:', mse)

mse = mean_squared_error(y_test, lr_model.predict(X_test))
print('Mean Squared Error:', mse)
